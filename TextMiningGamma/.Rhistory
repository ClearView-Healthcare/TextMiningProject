shiny::runApp('R/Tweeter/TextMining')
install.packages("fields")
runApp('R/Tweeter/TextMining')
install.packages("RTextTools")
runApp('R/Tweeter/TextMining')
?hclust
x <- file.choose()
extractContent <- function (x){
# num <-length(x$name)
num=1
textum <- vector()
for (i in 1:num) {
#  uris.name <- x$datapath[i]
text.scan <- scan(uris.name, what="character", sep="\n",blank.lines.skip = FALSE)
data=enc2utf8(text.scan)
#  for (i in 1:length(data)){
#   text<-data[i]
#  }
# text <- paste(data, collapse = " ")
# text <-gsub("-\\s+", "", text)
textum[i] <- data #text
}
return(textum)
}
extractContent(x)
extractContent <- function (x){
# num <-length(x$name)
num=1
textum <- vector()
for (i in 1:num) {
#  uris.name <- x$datapath[i]
uris.name=x
text.scan <- scan(uris.name, what="character", sep="\n",blank.lines.skip = FALSE)
data=enc2utf8(text.scan)
#  for (i in 1:length(data)){
#   text<-data[i]
#  }
# text <- paste(data, collapse = " ")
# text <-gsub("-\\s+", "", text)
textum[i] <- data #text
}
return(textum)
}
extractContent(x)
extractContent <- function (x){
# num <-length(x$name)
num=1
textum <- vector()
text<-vector()
for (i in 1:num) {
#  uris.name <- x$datapath[i]
uris.name=x
text.scan <- scan(uris.name, what="character", sep="\n",blank.lines.skip = FALSE)
data=enc2utf8(text.scan)
for (i in 1:length(data)){
text<-data[i]
}
# text <- paste(data, collapse = " ")
# text <-gsub("-\\s+", "", text)
textum[i] <- text
}
return(textum)
}
extractContent(x)
text.scan <- scan(uris.name, what="character", sep="\n",blank.lines.skip = FALSE)
uris.name=x
text.scan <- scan(uris.name, what="character", sep="\n",blank.lines.skip = FALSE)
data=enc2utf8(text.scan)
data
length(data)
text<-vector()
for (y in 1:length(data)){
text[y]<-data
}
text
data[2]
data[10]
extractContent <- function (x){
# num <-length(x$name)
num=1
textum <- list()
text<-vector()
for (i in 1:num) {
#  uris.name <- x$datapath[i]
uris.name=x
text.scan <- scan(uris.name, what="character", sep="\n",blank.lines.skip = FALSE)
data=enc2utf8(text.scan)
#  for (y in 1:length(data)){
#   text[y]<-data
#  }
# text <- paste(data, collapse = " ")
# text <-gsub("-\\s+", "", text)
textum[i] <- data
}
return(textum)
}
extractContent(x)
textum[i] <- data
textum <- list()
textum[1] <- data
textum <- c(textum,data)
textum
shiny::runApp('R/Tweeter/TextMining')
?HTML
runApp('R/Tweeter/TextMining')
?read
?readPlain
?scan
y<-file.choose()
num <-c(x,y)
num
uris.name<-num[1]
text.scan <- scan(uris.name, what="character", sep="\n",blank.lines.skip = TRUE)
data=enc2utf8(text.scan)
data
class(data)
length(data)
text <-paste(data,sep="\n")
text
textum <- list()
textum[1] <-text
textum
for (y in 1:length(data)) {
text <-c(text,data[y])
}
text
for (y in 1:length(data)) {
text <-list(text,data[y])
}
text
as.list(data)
as.vector(data)
textum[[1] <-text
textum[[1]] <-text
textum
data=enc2utf8(text.scan)
textum[[1]] <-data
textum
runApp('R/Tweeter/TextMining')
runApp('R/Tweeter/TextMining')
?paset
?paste
runApp('R/Tweeter/TextMining')
paste(textum,collapse="\n")
paste(textum,"\n")
paste(textum,sep="\n")
paste(textum,sep="\n")
paste(textum,collapse="\n")
data1<-paste(data,sep="\n")
data1
textum[[1]] <-data1
textum
runApp('R/Tweeter/TextMining')
?paste0
runApp('R/Tweeter/TextMining')
text.scan <- scan(uris.name, what="character", sep="",blank.lines.skip = TRUE)
text.scan
?scan
data1<-paste(data,"\n")
data1
runApp('R/Tweeter/TextMining')
textum
textum <- list()
textum[[1]] <-data1
textum
textum[[1]] <-data
textum
runApp('R/Tweeter/TextMining')
textum <- vector()
textum[[i]] <-data
textum[[1]] <-data
textum[1] <-data
textum
textum[1] <-data[1]
textum[2] <- data[2]
textum
text[[1]] <- textum
text
text[[1]] <- data
text
runApp('R/Tweeter/TextMining')
runApp('R/Tweeter/TextMining')
length(textum)
length(textum[[1]])
textum
data=enc2utf8(text.scan)
textum[[i]] <-data
textum[[1]] <-data
textum <- list()
textum[[1]] <-data
length(textum[[1]])
print(textum[[1]][1])
print(textum[[1]][2])
print(textum[[1]])
text.scan <- scan(uris.name, what="character", sep="\n",blank.lines.skip = TRUE)
data=enc2utf8(text.scan)
textum[[1]] <-data
print(textum[[1]])
print(textum[[1]][1])
runApp('R/Tweeter/TextMining')
?HTML
runApp('R/Tweeter/TextMining')
?lapply
runApp('R/Tweeter/TextMining')
runApp('R/Tweeter/TextMining')
data1<-paste(data," ")
data1
data1<-paste(data,sep=" ")
data1
data1<-paste(data,collapse=" ")
data1
data1 <- sub("-\\s+","-",data1)
data1
textum[[1]] <-data1
textum
textum <- unlist(textum)
textum
data1 <- sub("\\s+","\\s",data1)
data1
data1<- sub("\\s+"," ",data1)
data1
data1<- sub("\\s+","",data1)
data1
data1<-paste(data,collapse=" ")
data1 <- gsub("-\\s+","-",data1)
data1<- gsub("\\s\\s+","",data1)
data1
data
data1<-paste(data,collapse=" ")
data1
data1<- gsub("\\s\\s+"," ",data1)
data1
runApp('R/Tweeter/TextMining')
shiny::runApp('R/TextMiningBeta')
runApp('R/TextMiningBeta')
install.packages("igraph")
install.packages("network")
install.packages("igraph")
setwd("~/R/Tweeter/Polnet2015/Data")
nodes <- read.csv("Dataset1-Media-Example-NODES.csv", header=T, as.is=T)
links <- read.csv("Dataset1-Media-Example-EDGES.csv", header=T, as.is=T)
head(nodes)
head(links)
nrow(nodes); length(unique(nodes$id))
nrow(links); nrow(unique(links[,c("from", "to")]))
links <- aggregate(links[,3], links[,-3], sum)
links <- links[order(links$from, links$to),]
colnames(links)[4] <- "weight"
rownames(links) <- NULL
net <- graph.data.frame(links, nodes, directed=T)
library(igraph)
net <- graph.data.frame(links, nodes, directed=T)
net
plot(net)
net <- simplify(net, remove.multiple = F, remove.loops = T)
plot(net)
plot(net, edge.arrow.size=.4,vertex.label=NA)
plot(net, edge.arrow.size=.4, edge.curved=.1)
plot(net, edge.arrow.size=.2, edge.color="orange",
vertex.color="orange", vertex.frame.color="#ffffff",
vertex.label=V(net)$media, vertex.label.color="black")
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
x <- paste("The/at grand/jj jury/nn commented/vbd on/in a/at number/nn of/in",
"other/ap topics/nns ,/, among/in them/ppo the/at Atlanta/np and/cc",
"Fulton/np-tl County/nn-tl purchasing/vbg departments/nns which/wdt",
"it/pps said/vbd ``/`` are/ber well/ql operated/vbn and/cc follow/vb",
"generally/rb accepted/vbn practices/nns which/wdt inure/vb to/in the/at",
"best/jjt interest/nn of/in both/abx governments/nns ''/'' ./.")
vs <- VectorSource(x)
elem <- getElem(stepNext(vs))
(doc <- readTagged()(elem, language = "en", id = "id1"))
tagged_words(doc)
elem
setwd("~/Documents/CL/Latex/Beamer_presentations/TLT2017/tlt15/flamenca")
x <-scan(file="E1_992TNT.txt", what="character")
x
x <-scan(file="E1_992TNT.txt", what="character",sep="\n")
x
vs <- VectorSource(x)
elem <- getElem(stepNext(vs))
elem
y <- gsub("\t","\",x)
)
""
)
\
"
y <- gsub("\t","/",x)
y
z<-paste(y,collapse=" ")
z
vs <- VectorSource(z)
elem <- getElem(stepNext(vs))
elem
(doc <- readTagged()(elem, language = "en", id = "id1"))
tagged_words(doc)
shiny::runApp('~/R/TextMiningBeta')
words <- vector()
pos <- vector()
for (i in 1:length(y)){
w<- strsplit(y[i],"/")[1]
p <-strsplit(y[i],"/")[2]
words[i] <- w
pos[i] <- p
}
pos
y
strsplit(y[i],"/")[1]
strsplit(y[i],"/")[2]
w<- unlist(strsplit(y[i],"/")[1])
p <-unlist(strsplit(y[i],"/")[2])
p <-unlist(strsplit(y[i],"/")[2])
source('~/.active-rstudio-document')
p
w
w<- unlist(strsplit(y[i],"/")[[1]])
words[i] <- w
ws <- strsplit(w,"")[1]
ws
words <- vector()
pos <- vector()
for (i in 1:length(y)){
w<- unlist(strsplit(y[i],"/")[1])
ws <- unlist(strsplit(w,"")[1])
p <-unlist(strsplit(y[i],"/")[2])
ps <- unlist(strsplit(y[i],"")[2])
words[i] <- ws
pos[i] <- ps
}
words
ws <- unlist(strsplit(w," ")[1])
ps <- unlist(strsplit(y[i]," ")[2])
ws
ps
ps <- unlist(strsplit(y[i]," ")[2])
ps
ps <- unlist(strsplit(y[w]," ")[2])
ps
ws <- unlist(strsplit(w," ")[1])
ws
unlist(strsplit(w," ")[2])
words[i] <- ws
pos[i] <- os
ps <- unlist(strsplit(w," ")[2])
words[i] <- ws
pos[i] <- ps
pos
words
w
w[1]
w[2]
words <- vector()
pos <- vector()
for (i in 1:length(y)){
w<- unlist(strsplit(y[i],"/")[1])
p <- w[2]
words[i] <- w
pos[i] <- p
}
words <- paste(words,collapse=" ")s
words <- paste(words,collapse=" ")
pos <- paste(pos,collapse=" ")
pos
runApp('~/R/TextMiningBeta')
words <- vector()
poss <- vector()
ws<- unlist(strsplit(y[1],"/"))
ws
w <- ws[1]
p <- ws[2]
w
p
words[1] <- w
words
for (i in 1:length(y)){
ws<- unlist(strsplit(y[i],"/"))
w <- ws[1]
p <- ws[2]
words[i] <- w
poss[i] <- p
}
word <- paste(words,collapse=" ")
pos <- paste(poss,collapse=" ")
word
pos
runApp('~/R/TextMiningBeta')
runApp('~/R/TextMiningBeta')
?input
runApp('~/R/TextMiningBeta')
setwd("~/R/TextMiningBeta")
library("rsconnect", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
deployApp(appName="TextMiningBeta")
runApp()
deployApp(appName="TextMiningBeta")
deployApp(appName="TextMiningBeta")
runApp()
deployApp(appName="TextMiningBeta")
